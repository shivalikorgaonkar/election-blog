---
title: 'Election Blog #3: Polling Predictions'
author: Shivali Korgaonkar
date: '2024-09-22'
slug: election-blog-3
categories: []
tags: []
---

**Introduction**

There are numerous different resources that prospective voters can use to track an election. Almost every new outlet has their own poll, and major election tracking sites, like FiveThirtyEight, are publicly available for anyone to monitor. There's great debate surrounding the purpose and benefit of polls. These polls are especially useful for campaigns to track shifts in their support between states and districts. It can also allow citizens to see how fellow Americans are reacting to current events across the country. However, polls have significant limitations. Sampling errors, biased methodologies, and low response rates can skew results. Additionally, they may influence voter behavior who can see one candidate drastically succeeding in their state, convincing them to stay home on election day. Unexpected events or late voter shifts can drastically alter outcomes, making predictions unreliable, but they are still a useful resource for researchers to predict election outcomes based on history and voter preferences.

In this week's blog, I will be using individual polling sites to see how outcomes differ over time, as well as creating my own model based on these polls.

```{r libraries, include=FALSE}

library(car)
library(caret)
library(CVXR)
library(glmnet)
library(tidyverse)
library(dplyr)
library(lubridate)

# Load in presidential poll ratings
ratings_2016 <- read_csv('~/Downloads/president_polls_2016.csv')
ratings_2020 <- read_csv('~/Downloads/president_polls_2020.csv')
ratings_2024 <- read_csv('~/Downloads/president_polls_2024.csv')

# Personal Blog Theme
my_blog_theme <- function() {
  theme(
    panel.border = element_blank(),
    panel.background = element_rect(fill = "gray92"),
    plot.title = element_text(size = 18, hjust = 0.8, color = "gray16", face = "bold", family = "Times New Roman"), 
    plot.subtitle = element_text(size = 14, color = "black", hjust = 0.5, family = "Times New Roman"),
    axis.text.x = element_text(angle = 45, hjust = 1),
    axis.text = element_text(size = 10, family = "Times New Roman"),
    axis.line = element_line(colour = "black"),
    axis.title = element_text(size = 12, family = "Times New Roman"),
    legend.position = "right",
    legend.text = element_text(size = 12))
}

```

**Poll Ratings Grade Distribution**

```{r echo=FALSE}
##Extension 1
#Consider 2016-2024 pollster ratings from FiveThirtyEight. (1.) How much variation is there in pollster quality?

# 2016 Histogram of Poll Ratings
ratings_2016$grade <- factor(ratings_2016$grade, levels = c("A+", "A", "A-", "B+", "B", "B-", "C+", "C", "C-", "D", "NA"))
bar_2016_pollratings <- ratings_2016|>
  ggplot(mapping = aes(x = grade)) + 
  geom_bar(fill = "plum4") +
  labs(title = "2016 Poll Ratings Grade Distribution",
       x = "Grade",
       y = "Count") +
  my_blog_theme()
bar_2016_pollratings
```

Among the 2016 presidential election polls provided this week, letter grades were designated to disclose their reliability. The most common poll grades were A-, B, and C-, respectively.

```{r echo=FALSE, warning = FALSE}
# 2020 Histogram of Poll Ratings
ratings_2020 <- ratings_2020 |>
  rename(grade = fte_grade)

ratings_2020$grade <- factor(ratings_2020$grade, levels = c("A+", "A", "A-", "A/B", "B+", "B", "B-", "B/C", "C+", "C", "C-", "C/D", "F", "NA"))
bar_2020_pollratings <- ratings_2020|>
  ggplot(mapping = aes(x = grade)) + 
  geom_bar(fill = "sandybrown") +
  labs(title = "2020 Poll Ratings Grade Distribution",
       x = "Grade",
       y = "Count") +
  my_blog_theme()
bar_2020_pollratings
```
In 2020, the most common letter grades for the polls provided was overwhelmingly C, with a distant second of B/C. The letters grades are significantly lower graded than in 2016, and the distribution is left skewed. 

```{r echo=FALSE, warning = FALSE}
# 2024 Histogram of Poll Ratings
hist_2024_pollratings <- ratings_2024|>
  ggplot(mapping = aes(x = numeric_grade)) + 
  geom_histogram(bins = 15, fill = "darkseagreen", color = "snow3") +
  scale_x_reverse() +
  labs(title = "2024 Poll Ratings Grade Distribution",
       x = "Grade",
       y = "Count") +
  my_blog_theme()
hist_2024_pollratings
```
The grading scheme changes for 2024 to a 1-3 scale with 3 being the highest rating. There's a heavy emphasis on the higher score between the 2 and 3 range.

**Polling Averages**

```{r 2016, echo=FALSE, warning = FALSE}
# (2.) Using tools and knowledge you have gained so far, build a model (or ensemble model) that uses individual polls from 2016 (president_polls_2016.csv), 2020 (...2020.csv), and 2024 (...2024.csv). How does your model compare to the models this week in lab?

# Finding the end date average in 2016 polls
election_day_2016 <- as.Date("2016-11-08")

nat_ratings_2016 <- ratings_2016 |>
  mutate(enddate = as.Date(enddate, format = "%m/%d/%Y")) |>
  filter(state == "U.S.") |>
  group_by(enddate) |>
  summarize(mean(adjpoll_clinton),
            mean(adjpoll_trump)) |>
  rename(avg_clinton = "mean(adjpoll_clinton)",
         avg_trump = "mean(adjpoll_trump)")

nat_ratings_2016 <- nat_ratings_2016 |>
  pivot_longer(cols = c(avg_clinton, avg_trump),
               names_to = "candidate", values_to = "average") |>
  mutate(candidate = if_else(candidate == "avg_clinton", "Hillary Clinton", "Donald Trump")) |>
  rename(pct = average) |>
  mutate(days_until_election = as.numeric(difftime(election_day_2016, enddate, units = "days")),
         weeks_until_election = days_until_election / 7)

nat_pollagg_2016_plot <- nat_ratings_2016 |>
  ggplot(aes(x=enddate, y = pct, color = candidate)) +
  geom_point(alpha = 0.25, size = 1.5) +
  geom_smooth(se = FALSE, span = .08) +
  scale_x_date(date_labels = "%b %d") +
  scale_color_manual(values = c("firebrick3", "dodgerblue3")) +
  labs(x = "Date",
       y = "Average Poll Approval",
       title = "Polling Averages by Date, 2016") +
  my_blog_theme()
nat_pollagg_2016_plot


```

The graph above tracks poll approval ratings for Trump and Clinton for about one year before election day. After averaging the different 2016 polls, I was able to mark a point for everyday over the year before Election Day to see how predictions changed. There a few notable trends in this chart. For starters, there is a drastic dip in December 2015 for Trump. This sink in polls can likely be attributed to Trump calling for a complete shutdown on Muslim people entering the United States seeking refuge or citizenship. Additionally, before February 2016, the candidates followed each other in poll approval, meaning they rose and sunk together. Afterwards, their votes began to diverge, so when Clinton did well, Trump did not, and vice versa. This is because the party primaries began in 2016, so both parties had great division between nominees. The Republicans lost a more moderate Ted Cruz and Marco Rubio, while the democrats lost a more progressive Bernie Sanders.

```{r 2020, echo=FALSE, warning = FALSE}

# End date average
election_day_2020 <- as.Date("2020-11-03")
nat_ratings_2020 <- ratings_2020 |>
  mutate(enddate = as.Date(end_date, format = "%m/%d/%y")) |>
  filter((is.na(state))) |>
  filter(answer %in% c("Trump", "Biden")) |>
  filter(enddate >= as.Date("2019-11-01")) |>
  group_by(enddate, candidate_name) |>
  summarize(mean(pct)) |>
  rename(pct = "mean(pct)")|>
  mutate(days_until_election = as.numeric(difftime(election_day_2020, enddate, units = "days")),
         weeks_until_election = days_until_election / 7) |>
  rename(candidate = candidate_name)

  
# Each enddate average
nat_pollagg_2020_plot <- nat_ratings_2020 |>
  ggplot(aes(x=enddate, y = pct, color = candidate)) +
  geom_point(alpha = 0.25, size = 1.5) + 
  geom_smooth(se = FALSE, span = .08) + 
  scale_x_date(date_labels = "%b %d") + 
  scale_color_manual(values = c("firebrick3", "dodgerblue3")) +
  labs(x = "Date",
       y = "Average Poll Approval", 
       title = "Polling Averages by Date, 2020") + 
  my_blog_theme()
nat_pollagg_2020_plot

```
The 2020 poll approval chart does not display extreme dips and peaks like in 2016. There is a similar trend that follows before and after the primaries, but not as drastically, since there were no major candidates running against Trump in 2020. The polls find their predictions converge near election day, unlike in 2016 as well. Between April and July, Trump struggled to consistently raise his approval, as the COVID-19 pandemic was endangering millions of Americans everyday. George Floyd's death in May also sparked the beginning of the Black Lives Matter movement, which the former President had been unable to empathize with or address, explaining his low rating.

```{r 2024, echo=FALSE, warning = FALSE}

# Each enddate average
election_day_2024 <- as.Date("2024-11-05")
nat_ratings_2024 <- ratings_2024 |>
  mutate(enddate = as.Date(end_date, format = "%m/%d/%y")) |>
  filter((is.na(state))) |>
  filter(answer %in% c("Trump", "Harris")) |>
  filter(enddate >= as.Date("2023-11-01")) |>
  group_by(enddate, candidate_name) |>
  summarize(mean(pct)) |>
  rename(pct = "mean(pct)") |>
  mutate(days_until_election = as.numeric(difftime(election_day_2024, enddate, units = "days")),
         weeks_until_election = days_until_election / 7) |>
  rename(candidate = candidate_name)

nat_pollagg_2024_plot <- nat_ratings_2024 |>
  ggplot(aes(x=enddate, y = pct, color = candidate)) +
  geom_point(alpha = 0.25, size = 1.5) + 
  geom_smooth(se = FALSE, span = .08) + 
  scale_x_date(date_labels = "%b %d") + 
  scale_color_manual(values = c("firebrick3", "dodgerblue3")) +
  labs(x = "Date",
       y = "Average Poll Approval", 
       title = "Polling Averages by Date, 2024") + 
  ylim(35,50)+
  my_blog_theme()
nat_pollagg_2024_plot

```
The chaos of 2024's polls represents the chaos that has undergone politics over the past year. The blue line represents President Biden's polls until July 21, 2024 when he drops out of the race and endorses Kamala Harris. Trump and Biden generally matched each other, staying between the 40-45% approval range. However, after a disastrous first debate at the end of June, Biden's polls sink to 35%. Immediately after he drops out in July, the Democratic Party jolts upwards and continues to have a comfortable lead above Trump, despite the age of Harris' campaign, especially following the Democratic National Convention.

```{r include=FALSE, warning = FALSE}
####----------------------------------------------------------#
#### Regularized regression with polling data.
####----------------------------------------------------------#
# Read election results data. 
d_vote <- read_csv("~/Downloads/popvote_1948-2020.csv")
d_vote$party[d_vote$party == "democrat"] <- "DEM"
d_vote$party[d_vote$party == "republican"] <- "REP"

# Combine all national poll data (2016-2024)
combined_polls <- nat_ratings_2016 |>
  full_join(nat_ratings_2020) |>
  full_join(nat_ratings_2024)
```

**Comparing Nate Silver and G. Elliott Morris**

Nate Silver created the original FiveThirtyEight model that relies on looking at many different individual polls. Further away from Election Day, Silver relies on a prediction from the weighted average of the different polls, based on their pollster rating and sample size. Closer to Election Day, the trend line method puts greater emphasis, so polling averaging is less conservative. These adjustments for averaging include, likely voters, house effects, and age of polls. There's also adjustment to mitigate the upward bounce in polls following party conventions. Demographics are accounted for, but Silver believes fundamentals (ie. economic factors) cause too much noise to be heavily reliant on. This year, Silver made a few adjustments including the exclusion of COVID-related factors, serious third party candidates, "rematch elections", and ranked choice voting states.

G. Elliott Morris, who currently runs the FiveThirtyEight model, also uses a weighted average for his polling prediction, but he changed the two factors deciding its weight. Morris uses the 538 pollster rating score and the frequency of surveys the pollster has released in a short period of time. This contrasts Silver who uses sample size instead of history. Morris also now uses the Bayesian multi-level dynamic linear model, meaning his model takes polls, weights polls, adjusts polls, and averages polls simultaneously. The adjustments Morris includes have some overlap to Silver in third party candidates, house effect, and likely voter effect. However, he also includes mode of survey and partisanship adjustment. Morris also introduced a state effect adjustment that essentially looks at individual state polls/trends, and uses them predict the effect on a neighboring state.

Morris has greater emphasis on the fundamentals, which Silver labels as "too noisy." Morris has about a dozen political and economic indicators, which Silver worries about leading to "over-fitting," to address uncertainty that comes from just looking at polls.


**Sources**

I collaborated with Sammy Duggasani and Nick Dominguez to create this week's blog and polling presentation.

(https://muslimadvocates.org/wp-content/uploads/2019/06/Timeline-of-Record-of-Bigotry.pdf).