---
title: "grant"
author: "Shivali Korgaonkar"
date: "2024-10-29"
output: html_document
---


```{r}
# Process state-level polling data. 
d_pollav_state <- d_state_polls |> 
  group_by(year, state, party) |> 
  filter(weeks_left <= 8,
         state %in% c("Arizona", "Georgia", "Michigan", "Nevada", 
                      "North Carolina", "Pennsylvania", "Wisconsin"),
         year >= 1980) %>%
  mutate(mean_pollav = mean(poll_support, na.rm = TRUE)) |>
  top_n(1, poll_date) |> 
  rename(latest_pollav = poll_support) |>
  select(-c(weeks_left, days_left, poll_date, candidate, before_convention)) |>
  pivot_wider(names_from = party, values_from = c(latest_pollav, mean_pollav))
```

```{r, include = FALSE, warning = FALSE, message = FALSE, results = 'asis'}

####----------------------------------------------------------#
#### Simulation examples. 
####----------------------------------------------------------#

# Merge data.
d <- d_pollav_state |> 
  left_join(d_state_popvote, by = c("year", "state")) |>  
  left_join(d_popvote |> filter(party == "democrat"), by = "year") |> 
  filter(year >= 1980) |> 
  ungroup()

d <- d %>% mutate(incumbent = as.numeric(incumbent),
             incumbent_party = as.numeric(incumbent_party)*(1-incumbent))
             
d <- d %>% merge(d_econ %>% filter(quarter == 2), by = "year")

# Sequester states for which we have polling data for 2024. 
states.2024 <- unique(d$state[d$year == 2024])

# Subset and split data.
d <- d |> 
  filter(state %in% states.2024)

d_train <- d |> 
  filter(year < 2024)
d_test <- d |> 
  filter(year == 2024)

```

```{r, include = FALSE, warning = FALSE, message = FALSE, results = 'asis'}

# Create lagged variables in the main dataset 'd'
t <- d %>% 
  filter(year >= 2016) %>% 
  arrange(year) %>% 
  group_by(state) %>% 
  mutate(
    D_pv2p_lag1 = lag(D_pv2p, 1),
    R_pv2p_lag1 = lag(R_pv2p, 1), 
    D_pv2p_lag2 = lag(D_pv2p, 2),
    R_pv2p_lag2 = lag(R_pv2p, 2)
  )

d_test <- d_test %>% select_if(~ !any(is.na(.)))

# Add lagged variables to the test set for the year 2024
d_test <- d_test %>% left_join(t %>% filter(year == 2024) %>% 
                                 select(state, year, D_pv2p, R_pv2p, D_pv2p_lag1, R_pv2p_lag1, D_pv2p_lag2, R_pv2p_lag2), 
                               by = c("state", "year"))

# I used ChatGPT to get the intersection

# Identify common columns between train and test datasets
common_columns <- intersect(names(d_train), names(d_test))

# Keep only the common columns in d_train
d_train <- d_train %>% select(all_of(common_columns))
```

```{r, include = FALSE, warning = FALSE, message = FALSE, results = 'asis'}

# rescale polling averages

d_train <- d_train %>% mutate(
  latest_pollav_REP = latest_pollav_REP*(100/(latest_pollav_REP + latest_pollav_DEM)),
  latest_pollav_DEM = 100 - latest_pollav_REP,
  mean_pollav_REP = mean_pollav_REP*(100/(mean_pollav_REP + mean_pollav_DEM)),
  mean_pollav_DEM = 100 - mean_pollav_REP)

d_test <- d_test %>% mutate(
  latest_pollav_REP = latest_pollav_REP*(100/(latest_pollav_REP + latest_pollav_DEM)),
  latest_pollav_DEM = 100 - latest_pollav_REP,
  mean_pollav_REP = mean_pollav_REP*(100/(mean_pollav_REP + mean_pollav_DEM)),
  mean_pollav_DEM = 100 - mean_pollav_REP)
```

```{r, include = FALSE, warning = FALSE, message = FALSE, results = 'asis'}

# I used ChatGPT to help do the Elastic Net regression

# Prepare your features and target variables
features <- c("latest_pollav_REP", "latest_pollav_DEM", 
              "mean_pollav_REP", "mean_pollav_DEM","D_pv2p_lag1", "D_pv2p_lag2","R_pv2p_lag2", "R_pv2p_lag1") 

# Manually change 2020 and 2024 values

# Economic Variables

d_train$unemployment[d_train$year == 2020] <- d_econ$unemployment[d_econ$year == 2019 & d_econ$quarter == 4]

d_train$GDP_growth_quarterly[d_train$year == 2020] <- d_econ$GDP_growth_quarterly[d_econ$year == 2019 & d_econ$quarter == 4]

d_train$RDPI_growth_quarterly[d_train$year == 2020] <- d_econ$unemployment[d_econ$year == 2019 & d_econ$quarter == 4]

# June Approval (first day of September from FiveThirtyEight)

d_test$juneapp[d_test$party == "democrat"] <- 46.1 - 47

d_test$juneapp[d_test$party == "republican"] <- 43 - 52.5

# Standardize the features in the training set
d_train_scaled <- d_train %>% 
  mutate(across(all_of(features), scale))  # Standardize all features

# Create model matrices with the standardized training data
X_train_scaled <- model.matrix(~ ., data = d_train_scaled[, features])
y_R_train <- d_train$R_pv2p
y_D_train <- d_train$D_pv2p

# Standardize the features in the test set using the same scaling parameters as training
scaling_params <- d_train %>% select(all_of(features)) %>% 
  summarise(across(everything(), list(mean = mean, sd = sd), na.rm = TRUE))

d_test_scaled <- d_test %>%
  mutate(across(all_of(features), ~ (. - scaling_params[[paste0(cur_column(), "_mean")]]) / 
                scaling_params[[paste0(cur_column(), "_sd")]]))

X_test_scaled <- model.matrix(~ ., data = d_test_scaled[, features])

# Fit the Elastic Net model with standardized data
alpha_value <- 0.5  # You can adjust this for mixing LASSO (alpha = 1) and Ridge (alpha = 0)
model_R <- glmnet(X_train_scaled, y_R_train, alpha = alpha_value)
model_D <- glmnet(X_train_scaled, y_D_train, alpha = alpha_value)

# Cross-validation to find the best lambda
cv_model_R <- cv.glmnet(X_train_scaled, y_R_train, alpha = alpha_value)
cv_model_D <- cv.glmnet(X_train_scaled, y_D_train, alpha = alpha_value)

# Get the best lambda values
best_lambda_R <- cv_model_R$lambda.min
best_lambda_D <- cv_model_D$lambda.min

# Predict on the test set using the best lambda
d_test$predicted_R_pv2p <- as.numeric(predict(cv_model_R, newx = X_test_scaled, s = best_lambda_R))
d_test$predicted_D_pv2p <- as.numeric(predict(cv_model_D, newx = X_test_scaled, s = best_lambda_D))

# Determine predicted winner
d_test <- d_test %>% mutate(pred_winner = ifelse(predicted_R_pv2p >= predicted_D_pv2p, "R", "D"))

# Select relevant columns for final output
d_test %>% select(state, predicted_R_pv2p, predicted_D_pv2p, pred_winner)

```

# Visualize Feature Importance

```{r, echo = FALSE, warning = FALSE, message = FALSE, results = 'asis'}

# Used ChatGPT to make this graph

# Use the scaled training matrix for feature names
features <- colnames(X_train_scaled)

# Extract coefficients using the best lambda from the cross-validated models
coef_R <- as.vector(coef(cv_model_R, s = best_lambda_R))[-1]  # Exclude intercept
coef_D <- as.vector(coef(cv_model_D, s = best_lambda_D))[-1]  # Exclude intercept

# Ensure the number of features matches the length of coefficients
importance_df <- data.frame(
  Feature = features,
  Importance_R = abs(coef_R),  # Absolute values for feature importance
  Importance_D = abs(coef_D)
)

# Reshape data for ggplot
importance_long <- reshape2::melt(importance_df, id.vars = "Feature", 
                                  variable.name = "Model", 
                                  value.name = "Importance")

# Plot feature importance
ggplot(importance_long, aes(x = reorder(Feature, Importance), y = Importance, fill = Model)) +
  geom_bar(stat = "identity", position = "dodge") +
  coord_flip() +
  labs(title = "Feature Importance (Elastic Net)",
       x = "Features", y = "Absolute Coefficient (Feature Importance)") +
    scale_fill_manual(values = c("Importance_D" = "dodgerblue4", "Importance_R" = "firebrick1")) +
  theme_minimal() 

```

```{r, echo = FALSE, warning = FALSE, message = FALSE, results = 'asis'}

# I used ChatGPT for guidance on stylizing the kable table

d_test %>%
  select(state, predicted_R_pv2p, predicted_D_pv2p, pred_winner) %>%
  kable() %>%
  kable_styling("striped") %>%
  row_spec(which(d_test$pred_winner == "R"), background = "firebrick1") %>%
  row_spec(which(d_test$pred_winner == "D"), background = "dodgerblue4")
```


```{r, echo = FALSE, warning = FALSE, message = FALSE, results = 'asis'}

state_errors <- d_train %>% 
  filter(year %in% c(2016, 2020)) %>% 
  select(state, year, latest_pollav_DEM, latest_pollav_REP, D_pv2p, R_pv2p) %>% 
  mutate(
    D_error = latest_pollav_DEM - D_pv2p,  # Difference between DEM poll avg and actual
    R_error = latest_pollav_REP - R_pv2p   # Difference between REP poll avg and actual
  ) %>% 
  select(state, year, D_error, R_error) %>% 
  pivot_wider(
    names_from = year, 
    values_from = c(D_error, R_error), 
    names_sep = "_"
  ) %>% mutate(
    weighted_error = 0.5*abs(D_error_2016) + 0.5*abs(D_error_2020)) %>%
  select(state, weighted_error) %>% 
  rename(State = state, 'Weighted Error' = weighted_error) 

state_errors %>% kable() %>% kable_styling("striped")

```

Using the above weighted errors as standard deviations yields the following simulation breakdown.

```{r, echo = FALSE, warning = FALSE, message = FALSE, results = 'asis'}

# I used ChatGPT to help with encoding this simulation of the polling error

# Set seed and define number of simulations
set.seed(111)
n_simulations <- 10000

# Merge weighted errors with the test data
d_test <- d_test %>% 
  left_join(state_errors, by = c("state" = "State"))

# Initialize a data frame to store simulation results
simulation_results <- data.frame(
  state = rep(d_test$state, each = n_simulations),
  predicted_R_pv2p = numeric(n_simulations * nrow(d_test)),
  predicted_D_pv2p = numeric(n_simulations * nrow(d_test)),
  pred_winner = character(n_simulations * nrow(d_test)),
  stringsAsFactors = FALSE
)

# Perform simulations with state-specific standard deviations
for (i in 1:nrow(d_test)) {
  # Get the latest polling averages and standard deviation for the current state
  latest_R <- d_test$latest_pollav_REP[i]
  latest_D <- d_test$latest_pollav_DEM[i]
  polling_error_sd <- d_test$`Weighted Error`[i]
  
  # Simulate polling averages for both parties using the state-specific sd
  simulated_R <- rnorm(n_simulations, mean = latest_R, sd = polling_error_sd)
  simulated_D <- rnorm(n_simulations, mean = latest_D, sd = polling_error_sd)
  
  # Update the results data frame
  simulation_results$predicted_R_pv2p[((i - 1) * n_simulations + 1):(i * n_simulations)] <- simulated_R
  simulation_results$predicted_D_pv2p[((i - 1) * n_simulations + 1):(i * n_simulations)] <- simulated_D
  
  # Determine the winner based on simulated values
  simulation_results$pred_winner[((i - 1) * n_simulations + 1):(i * n_simulations)] <- ifelse(simulated_R >= simulated_D, "R", "D")
}

# Summarize results for Democrats
democrat_summary <- simulation_results %>%
  group_by(state) %>%
  summarise(D_win_percentage = mean(pred_winner == "D") * 100, .groups = 'drop')

# Display the summary table
democrat_summary %>%
  kable(col.names = c("State", "D Win Percentage")) %>%
  kable_styling("striped") %>%
  row_spec(0, bold = TRUE)
```

# Projections 

Using this model, our ultimate electoral college would look as follows, with Vice President Kamala Harris narrowly squeaking out a win.

```{r, echo = FALSE, warning = FALSE, message = FALSE, results = 'asis'}

# Display the electoral college map and chart
voting_results <- voting_results %>% mutate(party = if_else(state %in% c("michigan", "wisconsin", "nevada", "pennsylvania"), "Democrat", party)) %>% mutate(party = if_else(state %in% c("arizona", "georgia", "north carolina"), "Republican", party))

us_map <- us_map %>% select(-electors, -party) %>% left_join(voting_results, by = c("region" = "state"))

ggplot(data = us_map, aes(x = long, y = lat, group = group, fill = factor(party))) +
  geom_polygon(color = "black") +
  theme_minimal() +
  coord_fixed(1.3) +
  scale_fill_manual(values = c("Democrat" = "dodgerblue4", "Republican" = "firebrick1", "Toss Up" = "beige")) +
  labs(title = "2024 Base Electoral College Map", x = "", y = "", caption = "Hawaii is blue \nAlaska is red \nNebraska 2nd district is blue \nMaine's 2nd district is red", fill = "Party") +
  theme(
    panel.grid.major = element_blank(), 
    panel.grid.minor = element_blank(),
    axis.text = element_blank(),
    axis.ticks = element_blank()
  )

df_2024 <- voting_results %>%
  group_by(party) %>%
  summarise(electoral_votes = sum(electors, na.rm = TRUE)) %>%
  mutate(party = factor(party, levels = c("Democrat", "Toss Up", "Republican")))

ggplot(df_2024, aes(x = "", y = electoral_votes, fill = party)) +
  geom_bar(stat = "identity", width = .8) +
  geom_text(aes(label = electoral_votes), position = position_stack(vjust = 0.5), color = "black", size = 5) +
  scale_fill_manual(values = c("Democrat" = "dodgerblue4", "Toss Up" = "beige", "Republican" = "firebrick1")) +
  coord_flip() +
  theme_void() +
  theme(legend.position = "right", plot.title = element_text(hjust = 0.5)) + 
  labs(fill = "Party", title = "2024 Presidential Electoral College Base Prediction") +
  scale_y_continuous(limits = c(0, 538)) +
  geom_hline(yintercept = 270, color = "black", linetype = "dashed")